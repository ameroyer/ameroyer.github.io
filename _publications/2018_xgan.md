---
title: "XGAN: Unsupervised Image-to-Image Translation for Many-to-Many Mappings"
collection: publications
relid: 2018-icml-davu
paperurl: 'https://arxiv.org/abs/1711.05139'
slides: '/files/slides/[2018]XGAN-DAVU Workshop.pdf'
year: 2018
authors: '<span class="first_author">Am√©lie Royer</span>, Konstantinos Bousmalis, Stephan Gouws, Fred Bertsch, Inbar Mosseri, Forrester Cole, Kevin Murphy'
venue: 'Domain Adaptation for Visual Understanding Workshop at ICML/IJCAI/EJCAI 2018'
teaser: 'thumbs/pub/Stage_2017_thumb.png'
bibtex: |
  @article{DBLP:journals/corr/abs-1711-05139,
  <br>&nbsp;&nbsp;&nbsp;author = {Am\'{e}lie Royer and Konstantinos Bousmalis and Stephan Gouws and
  <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fred Bertsch and Inbar Mosseri and Forrester Cole and Kevin Murphy},
  <br>&nbsp;&nbsp;&nbsp;title = {{XGAN:} Unsupervised Image-to-Image Translation for many-to-many Mappings},
  <br>&nbsp;&nbsp;&nbsp;journal = {Domain Adaptation for Visual Understanding Workshop at ICML'18},
  <br>&nbsp;&nbsp;&nbsp;year = {2018}
  <br>}
---

Style transfer usually refers to the task of applying color and texture information from a specific style image to a given content image while preserving the structure of the latter. Here we tackle the more generic problem of semantic style transfer: given two unpaired collections of images, we aim to learn a mapping between the corpus-level style of each collection, while preserving semantic content shared across the two domains.

We introduce XGAN ("Cross-GAN"), a dual adversarial autoencoder, which captures a shared representation of the common domain semantic content in an unsupervised way, while jointly learning the domain-to-domain image translations in both directions. We exploit ideas from the domain adaptation literature and define a semantic consistency loss which encourages the model to preserve semantics in the learned embedding space. We report promising qualitative results for the task of face-to-cartoon translation. The cartoon dataset we collected for this purpose, CartoonSet, is publicly availale at https://google.github.io/cartoonset/index.html as a new benchmark for semantic style transfer.
