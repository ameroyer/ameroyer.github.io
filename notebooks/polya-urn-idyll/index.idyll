[meta title:"Polya Urn Idyll" description:"Short description of your
project" /]

[Header fullWidth:true title:"Pólya Urn" subtitle:"An interactive study of the Pólya urn model" author:"Amélie Royer"
authorLink:"https://pub.ist.ac.at/~aroyer/" date:`(new
Date()).toDateString()` background:"#222222" color:"#ffffff" /]


# Introduction

The Pólya urn model is a statistical experiment in which we study the distribution of two populations of distinctly colored balls in an urn. In its simplest form, the problem can be stated as follows:

[div className:"definition"]
Given an urn containing initially [equation]a[/equation]   [span className:"popa"] orange[/span] balls and [equation]b[/equation]   [span className:"popb"] blue[/span] balls, we pick one ball at random from the urn, place it back in the urn and add one new ball of the same color in the urn; We then repeat this sampling procedure [equation]n[/equation] times.
[/div]


[var name:"a0_fig_urn" value:1 type:int/]
[var name:"b0_fig_urn" value:2 type:int/]
[var name:"run_fig_urn" value:false /]

[div]
[Inline]
[button className:"simulate" onClick:`run_fig_urn = true`]
Simulate
[/button]
[/Inline]
Pólya urn with [equation]a =[/equation] [Dynamic value:a0_fig_urn max:12 min:1 display:`a0_fig_urn.toString()`/] and [equation]b =[/equation] [Dynamic value:b0_fig_urn max:12 min:1 display:`b0_fig_urn.toString()`/]
[/div]
[PolyaUrn className:"d3-component" state:state a0:a0_fig_urn b0:b0_fig_urn run:run_fig_urn /]


It is a good example of how small imbalances are magnified over time, as the more ball of one color are drawn the more they are likely to be drawn. In the following we study interesting probability quatities to understnad the dynamics of the model, and in particular with respect to the initial ratio.


# Basic dynamics of the model

### Composition of the urn at step n
Let us first express the *probability of having picked [equation]k[/equation] [span className:"popb"]blue[/span] objects after [equation]n \geq k[/equation] steps* of the experiment. Denoting by [equation]B_n[/equation] the number of blue balls at step  [equation]n[/equation], and by [equation]S_n[/equation] the sampling event at step [equation]n[/equation], taking value [span className:"popb"]1[/span] if a blue ball is sampled and  [span className:"popa"]0[/span] otherwise:

[Equation display:true]
\mathbb{P} (B_n = b + k) =   \sum_{\mathbf{s} \in {\{0, 1\}}^n \atop \sum_i \mathbf{s}_i = k}  \mathbb{P}(S_1 = s_1, \dots S_{n} = s_n)
[/Equation]


[Aside]
[div className:"detail"]
[Equation]\ \ \ \ \mathbb{P}(S_1 = s_1, \dots, S_{n} = s_n)[/Equation]
[Equation]= \mathbb{P}(S_1 = s_1)  \mathbb{P}(S_2 = s_2\ |\ S_1 = s_1) \dots[/Equation]
[/div]
[/Aside]


We can expand the inner term by using the probability [span className:"text_detail"]chain rule[/span]. Moreover, the probability of drawing a ball of a certain color is simply the ratio of correspondingly colored balls in the urn, which evolves with each sampling. Therefore, the conditional probability of drawing a [span className:"popb"]blue[/span]  can be written as:

[Aside][equation](1)[/equation][/Aside]
[Equation display:true]
\mathbb{P}(S_n = 1\ |\ S_{1} = s_1, \dots, S_{n-1} = s_{n-1}) =
\frac{b + \sum_{i = 1}^{n - 1} s_i}{a + b + n - 1}
[/Equation]

From this expression, we can see that the probability does not depend on the  time step [equation]n[/equation] but rather on *how many blue balls have been sampled until now*. In other words, for any sequence of draws [equation]\mathbf{s}[/equation], we can arrange the order in which the balls have been drawn without affecting the probability of the next draw. More formally, it means that **Equation (1)** is equivalent to:

[Aside][equation](2)[/equation][/Aside]
[Equation display:true]
\mathbb{P}(S_n = 1\ |\ S_{1} = \textcolor{CornflowerBlue}{1}, \dots,
S_{\bar{\mathbf{s}}} = \textcolor{CornflowerBlue}{1},
S_{\bar{\mathbf{s}} + 1} = \textcolor{Orange}{0} \dots S_{n-1} = \textcolor{Orange}{0}  )
[/Equation]

where [equation]\bar{\mathbf{s}}[/equation] is a shortcut notation for [equation]\sum_{i=1}^{n-1} s_i[/equation] from [equation](1)[/equation]. The same analysis holds for the conditional probability of drawing an orange ball. Bringing everything together, we can finally write
[Equation display:true]
\mathbb{P} (B_n = b + k) = \binom{n}{k} \mathbb{P}(S_1 =
\textcolor{CornflowerBlue}{1}, \dots, S_k = \textcolor{CornflowerBlue}{1}, S_{k+1} = \textcolor{Orange}{0} \dots S_{n} = \textcolor{Orange}{0})
[/Equation]
[Equation display:true]
= \binom{n}{k} \prod_{p=0}^{k-1} \frac{b + p}{a+ b + p}  \prod_{q=0}^{n-k-1} \frac{a + q}{a+ b + q}
[/Equation]
[Equation display:true]
= \binom{n}{k} \frac{(b+k-1)! (a+b-1)! (a+n-k-1)!}{(b-1)! (a-1)! (a+b+n-1)!}
[/Equation]


[div className:"equation"]
[Equation display:true]
\mathbb{P} (B_n = b + k) = \frac{\binom{n}{k} \binom{a+b}{b}}{\binom{a+b+n-1}{b+k}}  \frac{ab}{(a+b)(b+k)}
[/Equation]
[/div]


### Probability of the  next draw

Following the previous result, we can now compute the probability of *picking a [span className:"popb"]blue[/span] ball at step [equation]n + 1[/equation]*, independently of the state of the urn at time [equation]n [/equation]:

[equation display:true]
\mathbb{P} (S_{n + 1} = 1) = \sum_{k=0}^{n} \mathbb{P}(S_{n+1} = 1\ |\ B_{n} = b + k)\ \mathbb{P}(B_{n} = b + k)
[/equation]

[equation display:true]
= \sum_{k=0}^{n} \frac{b+k}{a+b+n}\ \mathbb{P}(B_{n} = b + k)
[/equation]

[Aside][equation](3)[/equation][/Aside]
[equation display:true]
= \frac{ab\binom{a+b}{b}}{(a+b+n)(a+b)} \underbrace{\sum_{k=0}^{n} \frac{\binom{n}{k}}{\binom{a+b+n-1}{b+k}}}_{f(n, a, b)}
[/equation]




[Aside]
[div className:"detail"]
Pascal's triangle: [Equation]\binom{n}{k} = \binom{n - 1}{k - 1} + \binom{n - 1}{k}[/Equation]
[/div]
[/Aside]

To simplify the expression of [equation]f(n, a, b)[/equation], we can use [span className:"text_detail"]Pascal's triangle formula[/span] on the numerator (while isolating the terms for [equation]j = 0[/equation] and [equation]j = n[/equation]) and observe that:
[Equation display:true]
f(n, a, b) = \sum_{j=0}^n \frac{\binom{n}{j}}{\binom{a+b+n-1}{b+j}}
[/Equation]

[Equation display:true]
= \frac{1}{\binom{a+b+n-1}{b}} + \frac{1}{\binom{a+b+n-1}{b+n}} + \sum_{j=1}^{n-1} \frac{\binom{n-1}{j}}{\binom{a+b+n-1}{b+j}} + \sum_{j=1}^{n-1} \frac{\binom{n-1}{j-1}}{\binom{a+b+n-1}{b+j}}
[/Equation]

[Equation display:true]
= \sum_{j=0}^{n-1} \frac{\binom{n-1}{j}}{\binom{a+b+n-1}{b+j}} + \sum_{j=0}^{n-1} \frac{\binom{n-1}{j}}{\binom{a+b+n-1}{b+ j +1}}
[/Equation]

[Equation display:true]
f(n, a, b) = f(n-1, a+1, b) + f(n-1, a, b+1)
[/Equation]

By extending the relation, one can infer and finally prove by induction over [equation]n[/equation], that [equation]f(n, a, b) = \frac{a+b+n}{(a+b) \binom{a+b-1}{b}}[/equation]. Plugging this expression in **Equation (3)**, we finally get:

[div className:"equation"]
[equation display:true]
\mathbb{P} (S_n = 1) = \frac{b}{a+b}
[/equation]
[/div]

In other words, the overall probability of the urn composition after [equation]n[/equation] only *depends on the initial color distribution in the urn*. In particular, for the case where [equation]a = 1[/equation] and [equation]b = 1[/equation] we have 
[equation]\mathbb{P} (B_n = k + 1) = \frac{[\!|\ k \leq n \ |\!]}{n + 1}[/equation] and [equation]\mathbb{P} (S_n = 1) = 0.5[/equation]. In other words, all urn configurations are equiprobable.




# Asymptotic Behaviour

### Expected Value

Since various urn compositions can be reached from the same initiation configuration  ([span className:"popa"][equation]a[/equation][/span], [span className:"popb"][equation]b[/equation][/span]),  one can also wonder what the urn would look like asymptotically, when the number of repeats [equation]n[/equation] goes to [equation] \infty[/equation].


Let us introduce [equation]Y_n = \frac{B_n}{a + b +n}[/equation], the ratio of the two colored ball populations at step [equation]n[/equation]. Using the previous results, we can easily see that the expected value of [equation]Y_n[/equation] is equal to the initial ratio, independently of the time step:

[equation display:true]
\mathbb{E}(Y_n) = \sum_{k=0}^n \mathbb{P}(B_n = b + k) \frac{b + k}{a + b +n}
[/equation]

[equation display:true]
 = \sum_{k=0}^n \mathbb{P}(B_n = b + k) \mathbb{P}(S_n = 1\ |\ B_n = b + k) =  \mathbb{P}(S_n = 1) 
[/equation]

[div className:"equation"]
[equation display:true]
\mathbb{E}(Y_n) = \frac{b}{a + b} = Y_0
[/equation]
[/div]


[var name:"a0_fig_dynamics" value:1 type:int/]
[var name:"b0_fig_dynamics" value:2 type:int/]
[var name:"num_runs_fig_dynamics" value:70 type:int/]
[var name:"num_steps_fig_dynamics" value:100 type:int/]
[var name:"run_fig_dynamics" value:false /]


This can also be observed in simulations. Here, blue lines ( [span className:"legend_lines"]---[/span] ) represent the observed value of [equation]Y_n[/equation] for each timestep [equation] n \leq [/equation]  [Display value:num_steps_fig_dynamics format:"d" /]  for [Display value:num_runs_fig_dynamics format:"d" /]  different runs with the same initial conditions [equation]a[/equation] and [equation]b[/equation]. Red circles ( [span className:"legend_circles"]●[/span] ) mark the average of these values across runs, for each time step, hence serve as an approximation of [equation]\mathbb{E}(Y_n)[/equation].

[div]
[Inline]
[button className:"simulate" onClick:`run_fig_dynamics = true`]
Simulate
[/button]
[/Inline]
observed values of [equation]Y_n[/equation] with [equation]a =[/equation] [Dynamic value:a0_fig_dynamics max:12 min:1 display:`a0_fig_dynamics.toString()`/] and [equation]b =[/equation] [Dynamic value:b0_fig_dynamics max:12 min:1 display:`b0_fig_dynamics.toString()`/].
[/div]
[PolyaDynamics className:"d3-component" state:state a0:a0_fig_dynamics b0:b0_fig_dynamics run:run_fig_dynamics num_steps:100 num_runs: 60/]

### Distribution
Going further, we can also study the convergence *in distribution* of the random variable [equation]Y_n[/equation]. First we observe that the probability distribution of [equation]Y_n[/equation] is directly linked to the one of [equation]B_n[/equation], that we expressed earlier. Moreover, we can further simply the expression by making use of the [Gamma](https://en.wikipedia.org/wiki/Gamma_function) and [Beta](https://en.wikipedia.org/wiki/Beta_function) functions. This yields the following result:

[Equation display:true]
\mathbb{P}\left(Y_n = \frac{b + k}{a + b+ n}\right) = \mathbb{P} (B_n = b + k) = \frac{\binom{n}{k} \binom{a+b}{b}}{\binom{a+b+n-1}{b+k}}  \frac{ab}{(a+b)(b+k)}
[/Equation]

[Equation display:true]
= \binom{n}{k}\frac{ab \binom{a+b}{b}}{a + b} \frac{1}{\binom{a+b+n-1}{b+k}(b+k)} 
[/Equation]

[Equation display:true]
= \binom{n}{k} \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \frac{\Gamma(b + k) \Gamma(a + n - k)}{\Gamma(a + b + n)}
[/Equation]


[div className:"equation"]
[equation display:true]
\mathbb{P}\left(Y_n = \frac{b + k}{a + b+ n}\right)  = \binom{n}{k} \frac{B(b + k, a + n - k)}{B(a, b)}
[/equation]
[/div]

Where the Gamma and Beta functions are defined as [equation]\Gamma: x \mapsto (x - 1)![/equation] and [equation]B: (a, b) \mapsto \frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)} = \int_0^1 x^{a-1} (1-x)^{b-1}dx[/equation] respectively.

To prove a convergence in distribution, we want to look at *the limit of the repartition function* of [equation]Y_n[/equation], defined as [equation]F_{Y_n}(x) = \mathbb{P}(Y_n \leq x)[/equation], when the time step [equation]n \rightarrow \infty[/equation]. Using the previous simplified expression, we have:


[Equation display:true]
F_{Y_n} (t) = \sum_{k = 0}^{t (a + b+ n) - b} \mathbb{P}\left(Y_n = \frac{b + k}{a + b+ n}\right) 
[/Equation]


[Equation display:true]
= \frac{1}{B(a,b)} \int_0^1 \sum_{k=0}^{t(a+b+n) - b} \binom{n}{k} x^{b+k-1} (1 - x)^{a+n-k-1} dx
[/Equation]

[Aside][equation](4)[/equation][/Aside]
[Equation display:true]
= \frac{1}{B(a,b)} \int_0^1 x^{b-1} (1 - x)^{a-1} \underbrace{\sum_{k=0}^{t(a+b+n) - b} \binom{n}{k} x^{k} (1 - x)^{n-k}}_{g(x, t, n,a,b)} dx
[/Equation]

Thus [equation]g(x,t,n, a, b)[/equation] is the only term that depends on [equation]n[/equation]. It is clear that this term is linked to the Binomial function. More specifically, if we define the random variable [equation]X_n[/equation] with a binomial distribution of parameters [equation]n[/equation] and [equation]x \in [0, 1][/equation], then we have exactly [equation]g(x, t, n, a, b) = \mathbb{P}(X_n \leq t(a+b+n) - b)[/equation].

We can then apply the [Demoivre-Laplace theorem](https://en.wikipedia.org/wiki/De_Moivre%E2%80%93Laplace_theorem), which derives from the Central Limit theorem, and yields that, for large [equation]n[/equation], 

[Equation display:true]
g(x, t, n, ab) \simeq \Phi\left(\frac{n (t - x)}{\sqrt{nx(1-x)}} + \frac{t(a+b) - b}{\sqrt{nx(1-x)}}\right)
[/Equation]

where [equation]\Phi[/equation] is the repartition function of the standard Gaussian distribution, [equation]\mathcal{N}(0,1)[/equation], and is continuous and bounded. As a result, we have that:


[Equation display:true]
\text{lim}_{n \rightarrow \infty} g(x, t, n, ab) = \left\{\begin{array}{lr}
        1, & \text{if } t > x\\
        0, & \text{if } t < x
        \end{array}\right.
[/Equation]

By splitting the integral from **Equation (4)** at point [equation]t \in [0, 1][/equation], we can conlude that

[div className:"equation"]
[Equation display:true]
\text{lim}_{n \rightarrow \infty} F_{Y_n} (t) = \frac{1}{B(a,b)} \int_0^t x^{b-1} (1 - x)^{a-1} dx
[/Equation]
[/div]

In other words, the proportion of blue balls in the urn, [equation]Y_n[/equation], converges in distribution to the Beta distribution with parameters *[span className:"popb"]b[/span]* and  *[span className:"popa"]a[/span]* when [equation]n[/equation] grows.



# Generalized Polyà urn



Configuration can be done via the `idyll` field in `package.json`.

## Markup

Idyll is based on Markdown.

You can use familiar syntax to create **bold** (`**bold**` ) and
*italic* (``*italic*` ) styles,

* lists of items,

``` * lists * of * items, ```

1. and numbered 2. lists 3. of items,


``` 1. and numbered 2. lists 3. of items, ```

in addition to [hyperlinks](https://idyll-lang.org) and images:

![quill](static/images/quill.svg)

``` ![quill](static/images/quill.svg) ```

## Components

Components can be embedded using a bracket syntax:

``` [Range /] ```

and can contain nested content:

``` [Equation]e = mc^{2}[/Equation] ```

Components accept properties:

``` [Range value:x min:0 max:1 /] ```

that can be bound to variables to achieve interactivity (more in next
section).


A variety of components are included by default. See [all the
available components](https://idyll-lang.org/docs/components/). You
can also use any html tag, for example: `[div] A div! [/div]`.

To create your own, add it to the `components/` folder. There are
examples of how to use Idyll with React and D3 based components
already included.



## Interactivity

Here is how you can instantiate a variable and bind it to a component:

[var name:"exampleVar" value:5 /]

[Range min:0 max:10 value:exampleVar /] [Display value:exampleVar /]

``` [var name:"exampleVar" value:5 /]

[Range min:0 max:10 value:exampleVar /] [Display value:exampleVar /]
```

## Learn More

To learn more see the documentation at https://idyll-lang.org/docs/,
join our [chatroom](https://gitter.im/idyll-lang/Lobby), or see the
project on [GitHub](https://github.com/idyll-lang/idyll).

[hr /]

# Technical Details

## Installation

- Make sure you have `idyll` installed (`npm i -g idyll`).  Clone this
- repo and run `npm install`.

## Developing a post locally

Run `idyll`.

## Building a post for production

Run `idyll build`. The output will appear in the top-level `build`
folder. To change the output location, change the `output` option in
`package.json`.

## Deploying

Make sure your post has been built, then deploy the docs folder via
any static hosting service.

## Dependencies

You can install custom dependencies by running `npm install
<package-name> --save`. Note that any collaborators will also need
download the package locally by running `npm install` after pulling
the changes.
